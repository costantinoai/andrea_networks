{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.vision.all import *\n",
    "from kornia import rgb_to_grayscale\n",
    "import torch.nn as nn\n",
    "import warnings\n",
    "import random, textwrap\n",
    "import os, glob\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import skimage\n",
    "from skimage.util import random_noise\n",
    "from skimage import util\n",
    "from skimage import exposure\n",
    "from scipy import ndimage\n",
    "from datetime import datetime\n",
    "import torch\n",
    "import torch.utils.model_zoo\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision.datasets as datasets\n",
    "from pathlib import Path\n",
    "import collections\n",
    "import seaborn as sn\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "defaults.device = torch.device('cuda')\n",
    "\n",
    "seed = 30\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "sn.set(style=\"darkgrid\")\n",
    "\n",
    "# stim_path = Path(r'D:\\Andrea_NN\\stimuli\\no_transf')\n",
    "stim_path = Path(r'D:\\Andrea_NN\\stimuli\\samediff')\n",
    "\n",
    "epochs = 1000\n",
    "cycles = 1\n",
    "batch_sz = 24\n",
    "lr_min = 1e-3\n",
    "weight_decay = 1e-3\n",
    "w_dropout_1 = 0.8\n",
    "w_dropout_2 = 0.8\n",
    "fov_noise = False\n",
    "\n",
    "\n",
    "class SiameseNetEncoderFB(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SiameseNetEncoderFB, self).__init__()\n",
    "\n",
    "        # V1 layers\n",
    "        self.V1_p = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=7 // 2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1),\n",
    "        )\n",
    "\n",
    "        # V2 layers\n",
    "        self.V2_p = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=3 // 2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1),\n",
    "        )\n",
    "\n",
    "        # V4 layers\n",
    "        self.V4_p = nn.Sequential(\n",
    "            nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=3 // 2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1),\n",
    "        )\n",
    "\n",
    "        # IT layers\n",
    "        self.IT_p = nn.Sequential(\n",
    "            nn.Conv2d(256, 512, kernel_size=3, stride=1, padding=3 // 2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1),\n",
    "        )\n",
    "\n",
    "        # V1 layers\n",
    "        self.V1_f = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=7, stride=2,\n",
    "                      padding=7 // 2),  # + self.vfb,\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1),\n",
    "        )\n",
    "\n",
    "        # V2 layers\n",
    "        self.V2_f = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=3 // 2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1),\n",
    "        )\n",
    "\n",
    "        # V4 layers\n",
    "        self.V4_f = nn.Sequential(\n",
    "            nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=3 // 2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1),\n",
    "        )\n",
    "\n",
    "        # IT layers\n",
    "        self.IT_f = nn.Sequential(\n",
    "            nn.Conv2d(256, 512, kernel_size=3, stride=1, padding=3 // 2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1),\n",
    "        )\n",
    "\n",
    "        # head\n",
    "        self.head = nn.Sequential(\n",
    "            AdaptiveConcatPool2d(),\n",
    "            nn.Flatten(),\n",
    "            nn.BatchNorm1d(1024 * 2,\n",
    "                           eps=1e-05,\n",
    "                           momentum=0.1,\n",
    "                           affine=True,\n",
    "                           track_running_stats=True),\n",
    "            nn.Dropout(p=w_dropout_1, inplace=False),\n",
    "            nn.Linear(in_features=1024 * 2, out_features=512, bias=False),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.BatchNorm1d(512,\n",
    "                           eps=1e-05,\n",
    "                           momentum=0.1,\n",
    "                           affine=True,\n",
    "                           track_running_stats=True),\n",
    "            nn.Dropout(p=w_dropout_2, inplace=False),\n",
    "            nn.Linear(in_features=512, out_features=2, bias=False),\n",
    "        )\n",
    "\n",
    "        self.fb = nn.Sequential(\n",
    "            nn.Conv2d(1024, 3, kernel_size=3, stride=1, padding=221),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1),\n",
    "        )\n",
    "\n",
    "    def forward(self, inp):\n",
    "        inp1 = inp[0]\n",
    "        inp2 = inp[1]\n",
    "        fov_inp = inp[2]\n",
    "\n",
    "        # perihperal 1\n",
    "        v1_p1 = self.V1_p(inp1)\n",
    "        v2_p1 = self.V2_p(v1_p1)\n",
    "        v4_p1 = self.V4_p(v2_p1)\n",
    "        vIT_p1 = self.IT_p(v4_p1)\n",
    "\n",
    "        # perihperal 1\n",
    "        v1_p2 = self.V1_p(inp2)\n",
    "        v2_p2 = self.V2_p(v1_p2)\n",
    "        v4_p2 = self.V4_p(v2_p2)\n",
    "        vIT_p2 = self.IT_p(v4_p2)\n",
    "\n",
    "        out_cat = torch.cat((vIT_p1, vIT_p2), 1)\n",
    "\n",
    "#         fb = self.fb(out_cat)\n",
    "#         try:\n",
    "#             v1_fov = self.V1_f(fb + fov_inp)\n",
    "#         except:\n",
    "#             v1_fov = self.V1_f(fov_inp)\n",
    "\n",
    "#         v2_fov = self.V2_f(v1_fov)\n",
    "#         v4_fov = self.V4_f(v2_fov)\n",
    "#         vIT_fov = self.IT_f(v4_fov)\n",
    "\n",
    "#         out_all = torch.cat((vIT_p1 + vIT_fov, vIT_p2 + vIT_fov), 1)\n",
    "#         out_all = torch.cat((vIT_p1, vIT_p2, vIT_fov), 1)\n",
    "        out_all = torch.cat((vIT_p1, vIT_p2), 1)\n",
    "    \n",
    "        out = self.head(out_all)\n",
    "\n",
    "        return out\n",
    "    \n",
    "\n",
    "def label_func(path):\n",
    "    split_name = path.stem.split(\"_\")\n",
    "    return 0 if split_name[-1] == split_name[-2] else 1\n",
    "\n",
    "\n",
    "def get_img_tuple_no_noise(path):\n",
    "    pair = Image.open(path)\n",
    "\n",
    "    label = label_func(Path(path))\n",
    "    orientation = os.path.basename(path).split(\"_\")[-3]\n",
    "\n",
    "    width, height = pair.size\n",
    "\n",
    "    if orientation == \"normal\":\n",
    "        left1, top1, right1, bottom1 = width - width // 4, 0, width, height // 4\n",
    "        left2, top2, right2, bottom2 = 0, height - height // 4, width // 4, height\n",
    "    else:\n",
    "        left1, top1, right1, bottom1 = 0, 0, width // 4, height // 4\n",
    "        left2, top2, right2, bottom2 = (\n",
    "            width - width // 4,\n",
    "            height - height // 4,\n",
    "            width,\n",
    "            height,\n",
    "        )\n",
    "\n",
    "    im1 = pair.crop((left1, top1, right1, bottom1)).resize((224, 224))\n",
    "    im2 = pair.crop((left2, top2, right2, bottom2)).resize((224, 224))\n",
    "    im3 = Image.new(\"RGB\", (224, 224), (125, 125, 125))\n",
    "\n",
    "    return (\n",
    "        ToTensor()(PILImage(im1)),\n",
    "        ToTensor()(PILImage(im2)),\n",
    "        ToTensor()(PILImage(im3)),\n",
    "        label,\n",
    "    )\n",
    "\n",
    "\n",
    "def get_img_tuple_noise(path):\n",
    "    pair = Image.open(path)\n",
    "\n",
    "    label = label_func(Path(path))\n",
    "    orientation = os.path.basename(path).split(\"_\")[-3]\n",
    "\n",
    "    width, height = pair.size\n",
    "\n",
    "    if orientation == \"normal\":\n",
    "        left1, top1, right1, bottom1 = width - width // 4, 0, width, height // 4\n",
    "        left2, top2, right2, bottom2 = 0, height - height // 4, width // 4, height\n",
    "    else:\n",
    "        left1, top1, right1, bottom1 = 0, 0, width // 4, height // 4\n",
    "        left2, top2, right2, bottom2 = (\n",
    "            width - width // 4,\n",
    "            height - height // 4,\n",
    "            width,\n",
    "            height,\n",
    "        )\n",
    "\n",
    "    im1 = pair.crop((left1, top1, right1, bottom1)).resize((224, 224))\n",
    "    im2 = pair.crop((left2, top2, right2, bottom2)).resize((224, 224))\n",
    "    im3 = Image.new(\"RGB\", (224, 224), (125, 125, 125))\n",
    "    im3 = Image.fromarray(\n",
    "        np.uint8(\n",
    "            skimage.util.random_noise(\n",
    "                skimage.img_as_float(im3), mode=\"s&p\", amount=1) * 255))\n",
    "\n",
    "    return (\n",
    "        ToTensor()(PILImage(im1)),\n",
    "        ToTensor()(PILImage(im2)),\n",
    "        ToTensor()(PILImage(im3)),\n",
    "        label,\n",
    "    )\n",
    "\n",
    "\n",
    "class ImageTuple(fastuple):\n",
    "    @classmethod\n",
    "    def create(cls, fns):\n",
    "        return cls(fns)\n",
    "\n",
    "    def show(self, ctx=None, **kwargs):\n",
    "        t1, t2, t3 = self\n",
    "        if (not isinstance(t1, Tensor) or not isinstance(t2, Tensor)\n",
    "                or t1.shape != t2.shape):\n",
    "            return ctx\n",
    "        line = t1.new_zeros(t1.shape[0], t1.shape[1], 10)\n",
    "        return show_image(torch.cat([t1, line, t2], dim=2), ctx=ctx, **kwargs)\n",
    "\n",
    "\n",
    "def ImageTupleBlock():\n",
    "    return TransformBlock(type_tfms=ImageTuple.create,\n",
    "                          batch_tfms=IntToFloatTensor)\n",
    "\n",
    "\n",
    "def get_tuples_no_noise(files):\n",
    "    return [[\n",
    "        get_img_tuple_no_noise(f)[0],\n",
    "        get_img_tuple_no_noise(f)[1],\n",
    "        get_img_tuple_no_noise(f)[2],\n",
    "        get_img_tuple_no_noise(f)[3],\n",
    "    ] for f in files]\n",
    "\n",
    "\n",
    "def get_tuples_noise(files):\n",
    "    return [[\n",
    "        get_img_tuple_noise(f)[0],\n",
    "        get_img_tuple_noise(f)[1],\n",
    "        get_img_tuple_noise(f)[2],\n",
    "        get_img_tuple_noise(f)[3],\n",
    "    ] for f in files]\n",
    "\n",
    "\n",
    "def get_x(t):\n",
    "    return t[:3]\n",
    "\n",
    "\n",
    "def get_y(t):\n",
    "    return t[3]\n",
    "\n",
    "\n",
    "def make_dls(stim_path, batch_sz=24, fov_noise=False):\n",
    "    stim_path = Path(stim_path)\n",
    "    pairs = glob.glob(os.path.join(stim_path, \"*.png\"))\n",
    "    fnames = sorted(Path(s) for s in pairs)\n",
    "    y = [label_func(item) for item in fnames]\n",
    "\n",
    "    splitter = TrainTestSplitter(test_size=0.2,\n",
    "                                 random_state=42,\n",
    "                                 shuffle=True,\n",
    "                                 stratify=y)\n",
    "    splits = splitter(fnames)\n",
    "    # splits = RandomSplitter()(fnames)\n",
    "    if fov_noise:\n",
    "        siamese = DataBlock(\n",
    "            blocks=(ImageTupleBlock, CategoryBlock),\n",
    "            get_items=get_tuples_noise,\n",
    "            get_x=get_x,\n",
    "            get_y=get_y,\n",
    "            splitter=splitter,\n",
    "        )\n",
    "    else:\n",
    "        siamese = DataBlock(\n",
    "            blocks=(ImageTupleBlock, CategoryBlock),\n",
    "            get_items=get_tuples_no_noise,\n",
    "            get_x=get_x,\n",
    "            get_y=get_y,\n",
    "            splitter=splitter,\n",
    "        )\n",
    "\n",
    "    dls = siamese.dataloaders(\n",
    "        fnames,\n",
    "        bs=batch_sz,\n",
    "        seed=seed,\n",
    "        # shuffle=True,\n",
    "        # device = 'cuda',\n",
    "    )\n",
    "    # check that train and test splits have balanced classes\n",
    "    train_test = [\"TRAIN\", \"TEST\"]\n",
    "    for train_test_id in [0, 1]:\n",
    "        s = 0\n",
    "        d = 0\n",
    "        for item in dls.__getitem__(train_test_id).items:\n",
    "            # print(label_from_path(item))\n",
    "            # print(item)\n",
    "            # print('---')\n",
    "            if item[3] == 1:\n",
    "                s += 1\n",
    "            else:\n",
    "                d += 1\n",
    "        print(\n",
    "            f\"{train_test[train_test_id]} SET (same, diff): {str(s)}, {str(d)}\"\n",
    "        )\n",
    "    return dls\n",
    "\n",
    "\n",
    "def plot_filters_multi_channel(t, path=\"\"):\n",
    "\n",
    "    # get the number of kernels\n",
    "    num_kernels = t.shape[0]\n",
    "\n",
    "    # define number of columns for subplots\n",
    "    num_cols = 12\n",
    "    # rows = num of kernels\n",
    "    num_rows = num_kernels\n",
    "\n",
    "    # set the figure size\n",
    "    fig = plt.figure(figsize=(num_cols, num_rows))\n",
    "\n",
    "    # looping through all the kernels\n",
    "    for i in range(t.shape[0]):\n",
    "        ax1 = fig.add_subplot(num_rows, num_cols, i + 1)\n",
    "\n",
    "        # for each kernel, we convert the tensor to numpy\n",
    "        npimg = np.array(t[i].numpy(), np.float32)\n",
    "\n",
    "        # standardize the numpy image\n",
    "        npimg = (npimg - np.mean(npimg)) / np.std(npimg)\n",
    "        npimg = np.minimum(1, np.maximum(0, (npimg + 0.5)))\n",
    "        npimg = npimg.transpose((1, 2, 0))\n",
    "        ax1.imshow(npimg)\n",
    "        ax1.axis(\"off\")\n",
    "        ax1.set_title(str(i))\n",
    "        ax1.set_xticklabels([])\n",
    "        ax1.set_yticklabels([])\n",
    "\n",
    "    plt.tight_layout()\n",
    "    if path != \"\":\n",
    "        plt.savefig(path)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def init_weights(net):\n",
    "    for m in net.modules():\n",
    "        if isinstance(m, (nn.Conv2d, nn.Linear)):\n",
    "            nn.init.xavier_uniform_(m.weight)\n",
    "            if m.bias is not None:\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "        elif isinstance(m, nn.BatchNorm2d):\n",
    "            m.weight.data.fill_(1)\n",
    "            m.bias.data.zero_()\n",
    "    return net\n",
    "\n",
    "\n",
    "def make_cf(cf_y, cf_pred, cycle, epoch, path=\"\"):\n",
    "    plt.figure(figsize=(7, 7))\n",
    "    cf_matrix = confusion_matrix(cf_y, cf_pred)\n",
    "    df_cm = pd.DataFrame(\n",
    "        cf_matrix,\n",
    "        index=[i for i in [\"Same\", \"Different\"]],\n",
    "        columns=[i for i in [\"Same\", \"Different\"]],\n",
    "    )\n",
    "    sn.heatmap(df_cm, annot=True, cbar=False, cmap=\"Blues\", fmt=\"d\")\n",
    "    plt.suptitle(f\"Epoch {cycle+1} x {epoch+1}\")\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"Actual\")\n",
    "    if path != \"\":\n",
    "        plt.savefig(os.path.join(path, f\"cm_{cycle+1}x{epoch+1}.png\"))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_losses(tr_loss, te_loss, cycle, epoch, path=\"\"):\n",
    "    plt.plot(tr_loss, label=\"Train\")\n",
    "    plt.plot(te_loss, label=\"Test\")\n",
    "    plt.suptitle(f\"Losses\\nEpoch {cycle+1} x {epoch+1}\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend()\n",
    "    if path != \"\":\n",
    "        plt.savefig(os.path.join(path, f\"loss_{cycle+1}x{epoch+1}.png\"))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_acc(tr_acc, te_acc, cycle, epoch, path=\"\"):\n",
    "    plt.plot(tr_acc, label=\"Train\")\n",
    "    plt.plot(te_acc, label=\"Test\")\n",
    "    plt.suptitle(f\"Accuracy\\nEpoch {cycle+1} x {epoch+1}\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.legend()\n",
    "    if path != \"\":\n",
    "        plt.savefig(os.path.join(path, f\"acc_{cycle+1}x{epoch+1}.png\"))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Due to IPython and Windows limitation, python multiprocessing isn't available now.\n",
      "So `number_workers` is changed to 0 to avoid getting stuck\n",
      "TRAIN SET (same, diff): 2688, 2688\n",
      "TEST SET (same, diff): 672, 672\n",
      "\n",
      "Train/Test started!\n",
      "    1 /     1 TRAIN/TEST losses: \t 341.26323533 \t 39.67501360 \t\t acc: \t 49.39 % \t 54.91 % \t\t time: 30.691\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: the launch timed out and was terminated",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-8d651ebeb200>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     86\u001b[0m             \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 88\u001b[1;33m             \u001b[0mtr_running_loss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     89\u001b[0m             \u001b[0mtr_total\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m             \u001b[0mtr_correct\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mpred\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\PyTorch\\lib\\site-packages\\fastai\\torch_core.py\u001b[0m in \u001b[0;36m__torch_function__\u001b[1;34m(self, func, types, args, kwargs)\u001b[0m\n\u001b[0;32m    338\u001b[0m         \u001b[0mconvert\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    339\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0m_torch_handled\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_opt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mconvert\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtypes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 340\u001b[1;33m         \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__torch_function__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtypes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    341\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mconvert\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconvert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mres\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    342\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mres\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTensorBase\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_meta\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mas_copy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\PyTorch\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36m__torch_function__\u001b[1;34m(cls, func, types, args, kwargs)\u001b[0m\n\u001b[0;32m    993\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    994\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0m_C\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDisableTorchFunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 995\u001b[1;33m             \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    996\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0m_convert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mret\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    997\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA error: the launch timed out and was terminated"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "dls = make_dls(stim_path, batch_sz, fov_noise)\n",
    "train_loader = dls.train\n",
    "test_loader = dls.valid\n",
    "\n",
    "# print('\\nShowing first batch...')\n",
    "# dls.show_batch(max_n = 2)\n",
    "# plt.show()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "net = SiameseNetEncoderFB().cuda()\n",
    "net = init_weights(net)\n",
    "\n",
    "url = f'https://s3.amazonaws.com/cornet-models/cornet_z-5c427c9c.pth'\n",
    "ckpt_data = torch.utils.model_zoo.load_url(url)\n",
    "\n",
    "state_dict = {\n",
    "    \"V1_p.0.weight\": ckpt_data['state_dict']['module.V1.conv.weight'],\n",
    "    \"V1_p.0.bias\": ckpt_data['state_dict']['module.V1.conv.bias'],\n",
    "    \"V2_p.0.weight\": ckpt_data['state_dict']['module.V2.conv.weight'],\n",
    "    \"V2_p.0.bias\": ckpt_data['state_dict']['module.V2.conv.bias'],\n",
    "    \"V4_p.0.weight\": ckpt_data['state_dict']['module.V4.conv.weight'],\n",
    "    \"V4_p.0.bias\": ckpt_data['state_dict']['module.V4.conv.bias'],\n",
    "    \"V1_f.0.weight\": ckpt_data['state_dict']['module.V1.conv.weight'],\n",
    "    \"V1_f.0.bias\": ckpt_data['state_dict']['module.V1.conv.bias'],\n",
    "    \"V2_f.0.weight\": ckpt_data['state_dict']['module.V2.conv.weight'],\n",
    "    \"V2_f.0.bias\": ckpt_data['state_dict']['module.V2.conv.bias'],\n",
    "    \"V4_f.0.weight\": ckpt_data['state_dict']['module.V4.conv.weight'],\n",
    "    \"V4_f.0.bias\": ckpt_data['state_dict']['module.V4.conv.bias'],\n",
    "    \"IT_f.0.weight\": ckpt_data['state_dict']['module.IT.conv.weight'],\n",
    "    \"IT_f.0.bias\": ckpt_data['state_dict']['module.IT.conv.bias'],\n",
    "    \"IT_p.0.weight\": ckpt_data['state_dict']['module.IT.conv.weight'],\n",
    "    \"IT_p.0.bias\": ckpt_data['state_dict']['module.IT.conv.bias'],\n",
    "}\n",
    "\n",
    "net.V1_p[0].weight.requires_grad = False\n",
    "net.V1_p[0].bias.requires_grad = False\n",
    "net.V2_p[0].weight.requires_grad = False\n",
    "net.V2_p[0].bias.requires_grad = False\n",
    "net.V4_p[0].weight.requires_grad = False\n",
    "net.V4_p[0].bias.requires_grad = False\n",
    "net.V1_f[0].weight.requires_grad = False\n",
    "net.V1_f[0].bias.requires_grad = False\n",
    "net.V2_f[0].weight.requires_grad = False\n",
    "net.V2_f[0].bias.requires_grad = False\n",
    "net.V4_f[0].weight.requires_grad = False\n",
    "net.V4_f[0].bias.requires_grad = False\n",
    "net.IT_f[0].weight.requires_grad = False\n",
    "net.IT_f[0].bias.requires_grad = False\n",
    "net.IT_p[0].weight.requires_grad = False\n",
    "net.IT_p[0].bias.requires_grad = False\n",
    "net.fb[0].weight.requires_grad = True\n",
    "net.fb[0].bias.requires_grad = True\n",
    "# net.head[0].bias.requires_grad = False\n",
    "\n",
    "net.load_state_dict(state_dict, strict=False)\n",
    "net = nn.DataParallel(net)\n",
    "net.to('cuda')\n",
    "\n",
    "params_to_update = net.parameters()\n",
    "optimizer = optim.Adam(filter(lambda p: p.requires_grad, params_to_update),\n",
    "                       lr=lr_min,\n",
    "                       weight_decay=weight_decay)\n",
    "\n",
    "print(\"\\nTrain/Test started!\")\n",
    "\n",
    "for cycle in range(cycles):\n",
    "    tr_loss = []\n",
    "    tr_acc = []\n",
    "    te_loss = []\n",
    "    te_acc = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        # TRAIN\n",
    "        net.train()\n",
    "\n",
    "        tr_running_loss = 0.0\n",
    "        tr_correct = 0\n",
    "        tr_total = 0\n",
    "        start = time.time()\n",
    "        for (inputs, labels) in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            out = net(inputs)\n",
    "            _, pred = torch.max(out, 1)\n",
    "            loss = criterion(out, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            tr_running_loss += loss.item()\n",
    "            tr_total += labels.size(0)\n",
    "            tr_correct += (pred == labels).sum().item()\n",
    "\n",
    "        tr_loss.append(tr_running_loss)\n",
    "        tr_acc.append(100 * tr_correct / tr_total)\n",
    "\n",
    "        # TEST\n",
    "        net.eval()\n",
    "\n",
    "        te_running_loss = 0.0\n",
    "        te_correct = 0\n",
    "        te_total = 0\n",
    "        cf_pred = []\n",
    "        cf_y = []\n",
    "        with torch.no_grad():\n",
    "            for (inputs, labels) in test_loader:\n",
    "                out = net(inputs)\n",
    "                _, pred = torch.max(out, 1)\n",
    "                loss = criterion(out, labels)\n",
    "                te_running_loss += loss.item()\n",
    "                te_total += labels.size(0)\n",
    "                te_correct += (pred == labels).sum().item()\n",
    "                cf_y += labels.cpu().detach().tolist()\n",
    "                cf_pred += pred.cpu().detach().tolist()\n",
    "\n",
    "            te_acc.append(100 * te_correct / te_total)\n",
    "            te_loss.append(te_running_loss)\n",
    "            end = time.time() - start\n",
    "            log_msg = f\"%5d / %5d TRAIN/TEST losses: \\t %.8f \\t %.8f \\t\\t acc: \\t %.2f %% \\t %.2f %% \\t\\t time: {round(end,3)}\" % (\n",
    "                cycle + 1,\n",
    "                epoch + 1,\n",
    "                tr_running_loss,\n",
    "                te_running_loss,\n",
    "                100 * tr_correct / tr_total,\n",
    "                100 * te_correct / te_total,\n",
    "            )\n",
    "            print(log_msg)\n",
    "\n",
    "path = ''\n",
    "make_cf(cf_y, cf_pred, cycle, epoch, path)\n",
    "plot_losses(tr_loss, te_loss, cycle, epoch, path)\n",
    "plot_acc(tr_acc, te_acc, cycle, epoch, path)\n",
    "\n",
    "# weights = net.module.V1_f[0].weight.data.cpu()\n",
    "# plot_filters_multi_channel(weights, path)\n",
    "# print(weights.shape)\n",
    "\n",
    "# weights = net.module.V1_p[0].weight.data.cpu()\n",
    "# plot_filters_multi_channel(weights, path)\n",
    "# print(weights.shape)\n",
    "\n",
    "# weights = net.module.fb[0].weight.data.cpu()\n",
    "# plot_filters_multi_channel(weights, path)\n",
    "# print(weights.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
